# Gesture Controlled Virtual Mouse and Voice Assistant  
### Hands-Free Interaction for Enhanced User Experience

## ğŸ§  Overview
This project introduces an AI-powered, hands-free humanâ€“computer interaction system that combines **gesture recognition** and **voice commands**. It allows users to control their computer using **hand gestures** detected via a webcam and **speech commands** for system operations, eliminating the need for traditional input devices like a mouse or keyboard.

---

## ğŸš€ Features
- ğŸ–ï¸ **Gesture Controlled Virtual Mouse** â€“ Move cursor, click, drag, and scroll using hand gestures captured by a webcam.  
- ğŸ™ï¸ **Voice Assistant** â€“ Execute commands like opening applications, searching online, or controlling system functions using speech.  
- âš™ï¸ **Real-Time Detection** â€“ Smooth and responsive performance using OpenCV and MediaPipe.  
- ğŸ§© **Accessible and Inclusive** â€“ Helps physically challenged users operate computers effortlessly.  
- ğŸ’» **Cross-Platform Support** â€“ Works on most systems with Python, webcam, and microphone.

---

## ğŸ§° Tech Stack
- **Programming Language:** Python  
- **Libraries Used:**  
  - OpenCV  
  - MediaPipe  
  - SpeechRecognition  
  - Pyttsx3  
  - NumPy  

---

## ğŸ—ï¸ System Requirements
- Python 3.8 or above  
- Webcam and Microphone  
- Required Libraries (install via pip):  
  ```bash
  pip install opencv-python mediapipe SpeechRecognition pyttsx3 numpy
  
ğŸ”§ Installation & Usage

Clone this repository:

git clone https://github.com/YourUsername/Gesture-Virtual-Mouse.git


Navigate to the project directory:

cd Gesture-Virtual-Mouse


Install dependencies (see above).

Run the main script:

python main.py


Use your hand gestures and voice commands to control your system hands-free!
ğŸŒ Applications

Accessibility for differently-abled users

Touchless control in hospitals, labs, or public spaces

Smart home and automation systems

Interactive AI systems and robotics


ğŸ§© Future Enhancements

Add gesture customization and training module

Integrate NLP-based conversational AI

Support for multiple languages and commands

GUI-based setup and calibration panel

ğŸ Conclusion

This project demonstrates the power of combining computer vision and speech recognition to enable intuitive, contactless computing. It redefines user interaction, making technology more natural, accessible, and efficient.

ğŸ‘¨â€ğŸ’» Contributors

Debasish Dey 
Shreyansh Kumar
